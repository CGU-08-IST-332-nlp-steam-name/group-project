{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "982d9f33-3e8f-425f-a20d-c16959465e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.9.1-cp312-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./venv/lib/python3.12/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch)\n",
      "  Downloading networkx-3.6-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Collecting fsspec>=0.8.5 (from torch)\n",
      "  Downloading fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.3)\n",
      "Downloading torch-2.9.1-cp312-none-macosx_11_0_arm64.whl (74.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m  \u001b[33m0:00:06\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
      "Downloading networkx-3.6-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: mpmath, sympy, networkx, fsspec, filelock, torch\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [torch]32m5/6\u001b[0m [torch]kx]\n",
      "\u001b[1A\u001b[2KSuccessfully installed filelock-3.20.0 fsspec-2025.12.0 mpmath-1.3.0 networkx-3.6 sympy-1.14.0 torch-2.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8f165ab-9ac7-4069-bece-ec0e2404a20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.12/site-packages (from transformers) (3.20.0)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.12/site-packages (from transformers) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.12/site-packages (from transformers) (6.0.3)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2025.11.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.12/site-packages (from transformers) (2.32.5)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests->transformers) (2025.11.12)\n",
      "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl (2.9 MB)\n",
      "Downloading regex-2025.11.3-cp312-cp312-macosx_11_0_arm64.whl (288 kB)\n",
      "Downloading safetensors-0.7.0-cp38-abi3-macosx_11_0_arm64.whl (447 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, safetensors, regex, hf-xet, huggingface-hub, tokenizers, transformers\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7/7\u001b[0m [transformers][0m [transformers]ub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed hf-xet-1.2.0 huggingface-hub-0.36.0 regex-2025.11.3 safetensors-0.7.0 tokenizers-0.22.1 tqdm-4.67.1 transformers-4.57.3\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b702b91-8ffe-4a40-affb-1a1ab0104539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.4.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in ./venv/lib/python3.12/site-packages (from gensim) (2.3.5)\n",
      "Collecting scipy>=1.7.0 (from gensim)\n",
      "  Downloading scipy-1.16.3-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting smart_open>=1.8.1 (from gensim)\n",
      "  Downloading smart_open-7.5.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting wrapt (from smart_open>=1.8.1->gensim)\n",
      "  Downloading wrapt-2.0.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
      "Downloading gensim-4.4.0-cp312-cp312-macosx_11_0_arm64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.16.3-cp312-cp312-macosx_14_0_arm64.whl (20.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading smart_open-7.5.0-py3-none-any.whl (63 kB)\n",
      "Downloading wrapt-2.0.1-cp312-cp312-macosx_11_0_arm64.whl (61 kB)\n",
      "Installing collected packages: wrapt, scipy, smart_open, gensim\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [gensim]2m3/4\u001b[0m [gensim]\n",
      "\u001b[1A\u001b[2KSuccessfully installed gensim-4.4.0 scipy-1.16.3 smart_open-7.5.0 wrapt-2.0.1\n"
     ]
    }
   ],
   "source": [
    "! pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d375b08-ee25-4099-a608-c0b408acad42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting contractions\n",
      "  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting textsearch>=0.0.21 (from contractions)\n",
      "  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
      "  Downloading anyascii-0.3.3-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
      "  Downloading pyahocorasick-2.2.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
      "Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading anyascii-0.3.3-py3-none-any.whl (345 kB)\n",
      "Downloading pyahocorasick-2.2.0-cp312-cp312-macosx_11_0_arm64.whl (33 kB)\n",
      "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [contractions]\n",
      "\u001b[1A\u001b[2KSuccessfully installed anyascii-0.3.3 contractions-0.1.73 pyahocorasick-2.2.0 textsearch-0.0.24\n"
     ]
    }
   ],
   "source": [
    "! pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a113256-27bc-4744-a02e-1de9a8d3bafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "import contractions\n",
    "# For progress bars\n",
    "# from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7fa11b-efff-441c-bbea-b66a4f4cb96f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf139347-38e0-4f03-b6d6-ccaa1842cfc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recommendationid</th>\n",
       "      <th>Appname</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>212664845</td>\n",
       "      <td>ARC Raiders</td>\n",
       "      <td>Addictive.  Stressful. Time waster.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>212664820</td>\n",
       "      <td>ARC Raiders</td>\n",
       "      <td>fuak arc\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>212664759</td>\n",
       "      <td>ARC Raiders</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>212664729</td>\n",
       "      <td>ARC Raiders</td>\n",
       "      <td>awesome game!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>212664705</td>\n",
       "      <td>ARC Raiders</td>\n",
       "      <td>If the Steam comments section is like every ot...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  recommendationid      Appname  \\\n",
       "0        212664845  ARC Raiders   \n",
       "1        212664820  ARC Raiders   \n",
       "2        212664759  ARC Raiders   \n",
       "3        212664729  ARC Raiders   \n",
       "4        212664705  ARC Raiders   \n",
       "\n",
       "                                         review_text  \n",
       "0                Addictive.  Stressful. Time waster.  \n",
       "1                                       fuak arc\\r\\n  \n",
       "2                                                  W  \n",
       "3                                      awesome game!  \n",
       "4  If the Steam comments section is like every ot...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_path = \"data/raw_reviews.csv\"\n",
    "\n",
    "review_df = pd.read_csv(review_path)[[\"recommendationid\", \"Appname\", \"review_text\"]]\n",
    "review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1c36513-e8fa-41c5-bd6c-daae049920e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69261, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84d5171e-2afa-4128-a38b-7e8d4598faea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recommendationid</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Appname</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7 Days to Die</th>\n",
       "      <td>300</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A Total War Saga: TROY</th>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC Raiders</th>\n",
       "      <td>300</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARK: Survival Ascended</th>\n",
       "      <td>300</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abiotic Factor</th>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>World of Warships</th>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yakuza 0</th>\n",
       "      <td>300</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRacing</th>\n",
       "      <td>300</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inZOI</th>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theHunter: Call of the Wild™</th>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>248 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              recommendationid  review_text\n",
       "Appname                                                    \n",
       "7 Days to Die                              300          299\n",
       "A Total War Saga: TROY                     300          300\n",
       "ARC Raiders                                300          299\n",
       "ARK: Survival Ascended                     300          299\n",
       "Abiotic Factor                             300          300\n",
       "...                                        ...          ...\n",
       "World of Warships                          100           99\n",
       "Yakuza 0                                   300          298\n",
       "iRacing                                    300          297\n",
       "inZOI                                      300          300\n",
       "theHunter: Call of the Wild™               300          300\n",
       "\n",
       "[248 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.groupby(\"Appname\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c759893bd90e9a3",
   "metadata": {},
   "source": [
    "# Part 1: Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e378b4b3201c1c67",
   "metadata": {},
   "source": [
    "## Contraction Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32ba9f6f05063e7d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3AL4Yj-8wdt4",
    "outputId": "f248a2c8-0f2f-4cc5-c5fc-99f2f0d28d38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in ./venv/lib/python3.12/site-packages (0.1.73)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in ./venv/lib/python3.12/site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: anyascii in ./venv/lib/python3.12/site-packages (from textsearch>=0.0.21->contractions) (0.3.3)\n",
      "Requirement already satisfied: pyahocorasick in ./venv/lib/python3.12/site-packages (from textsearch>=0.0.21->contractions) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions\n",
    "import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00bd1bb1-f5c1-4966-862e-5694b625cc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# review_df['review_text']\n",
    "review_df['review_text'] = review_df['review_text'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d8ebae2-e9d8-44a7-be9b-b84ad95d6f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48713, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# review_df.loc((review_df['review_text'].str.len() > 0)).shape\n",
    "review_df = review_df[\n",
    "    review_df[\"review_text\"].apply(lambda x: len(x) > 20)\n",
    "    ]\n",
    "review_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2459faf72fdd141",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "id": "uhAJIG4W0K76",
    "outputId": "0ee30b15-c72d-4b03-b436-07e6424d3461"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m review_df[\u001b[33m'\u001b[39m\u001b[33mreview_expanded\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mreview_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mreview_text\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43mcontractions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# review_df.iloc[0,2]\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m## contraction expansion doesn't work because the apostrophe's are being escaped with \\'\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.ws/group-project/venv/lib/python3.12/site-packages/pandas/core/series.py:4943\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4808\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4809\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4810\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4815\u001b[39m     **kwargs,\n\u001b[32m   4816\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4817\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4818\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4819\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4934\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4935\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4936\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4937\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4938\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4939\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4940\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4941\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4942\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4943\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.ws/group-project/venv/lib/python3.12/site-packages/pandas/core/apply.py:1422\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1421\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1422\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.ws/group-project/venv/lib/python3.12/site-packages/pandas/core/apply.py:1502\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1496\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1498\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1499\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1500\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1501\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1502\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1507\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1508\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.ws/group-project/venv/lib/python3.12/site-packages/pandas/core/base.py:925\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    923\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.ws/group-project/venv/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:2999\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 1\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m review_df[\u001b[33m'\u001b[39m\u001b[33mreview_expanded\u001b[39m\u001b[33m'\u001b[39m] = review_df[\u001b[33m'\u001b[39m\u001b[33mreview_text\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x:\u001b[43mcontractions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m.lower())\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# review_df.iloc[0,2]\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m## contraction expansion doesn't work because the apostrophe's are being escaped with \\'\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.ws/group-project/venv/lib/python3.12/site-packages/contractions/__init__.py:102\u001b[39m, in \u001b[36mfix\u001b[39m\u001b[34m(s, leftovers, slang)\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfix\u001b[39m(s, leftovers=\u001b[38;5;28;01mTrue\u001b[39;00m, slang=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    101\u001b[39m     ts = replacers[(leftovers, slang)]\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mts\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.ws/group-project/venv/lib/python3.12/site-packages/textsearch/__init__.py:564\u001b[39m, in \u001b[36mTextSearch.replace\u001b[39m\u001b[34m(self, text, return_entities)\u001b[39m\n\u001b[32m    562\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compare \u001b[38;5;129;01mand\u001b[39;00m compare \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m norm:\n\u001b[32m    563\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m564\u001b[39m start, stop, result = \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# maybe want to remove this\u001b[39;00m\n\u001b[32m    566\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.ws/group-project/venv/lib/python3.12/site-packages/textsearch/__init__.py:371\u001b[39m, in \u001b[36mTextSearch.bounds_check\u001b[39m\u001b[34m(self, text, start, stop, norm)\u001b[39m\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbounds_check\u001b[39m(\u001b[38;5;28mself\u001b[39m, text, start, stop, norm):\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(text) != stop \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mtext\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.right_bound_chars:\n\u001b[32m    372\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    373\u001b[39m     \u001b[38;5;66;03m# watch out... cannot just get index as we might risk -1\u001b[39;00m\n",
      "\u001b[31mIndexError\u001b[39m: string index out of range"
     ]
    }
   ],
   "source": [
    "review_df['review_expanded'] = review_df['review_text'].apply(lambda x:contractions.fix(x).lower())\n",
    "# review_df.iloc[0,2]\n",
    "\n",
    "## contraction expansion doesn't work because the apostrophe's are being escaped with \\'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b84561c317fce6",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "36b25a6a-1d57-4aa4-9de8-2c81e19734a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting click (from nltk)\n",
      "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting joblib (from nltk)\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./venv/lib/python3.12/site-packages (from nltk) (2025.11.3)\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.12/site-packages (from nltk) (4.67.1)\n",
      "Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Installing collected packages: joblib, click, nltk\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [nltk][32m2/3\u001b[0m [nltk]\n",
      "\u001b[1A\u001b[2KSuccessfully installed click-8.3.1 joblib-1.5.2 nltk-3.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "16604d5400214b06",
   "metadata": {
    "id": "8NUTjGFx2eqD"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a38a83ea9c223bec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "abQpHSZ72eXU",
    "outputId": "91a5a57a-036a-45c8-9dd8-890347f87cf0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            [Addictive, ., Stressful, ., Time, waster, .]\n",
       "4        [If, the, Steam, comments, section, is, like, ...\n",
       "5        [I, like, the, gathering, and, sneaking, aroun...\n",
       "6        [Very, well, made, game, ,, every, time, I, ho...\n",
       "7        [I, thought, this, would, be, too, sweaty, for...\n",
       "                               ...                        \n",
       "69256                       [We, have, Hades, at, home, :]\n",
       "69257    [Unfortunately, can, not, recommend, the, game...\n",
       "69258    [if, you, enjoy, soulstone, survivors, or, had...\n",
       "69259    [Great, game, overall, !, I, really, enjoy, th...\n",
       "69260    [The, game, is, pretty, good, for, some, of, t...\n",
       "Name: review_tokens, Length: 48713, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize each review\n",
    "review_df['review_tokens'] = review_df['review_text'].apply(wordpunct_tokenize)\n",
    "review_df['review_tokens']\n",
    "# review_df.iloc[0,3]\n",
    "\n",
    "## wordpunct tokenizer is handling the contractions and the tab characters well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1752e89a24ee3e82",
   "metadata": {},
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9794f14c276750ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PjJ_L8Vi2d5R",
    "outputId": "d16d50b3-e76d-486a-b3cb-a37c7575274e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/joh11678/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3ad75db36d5214d4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 494
    },
    "id": "XCasi5yE3XlJ",
    "outputId": "3c16d658-f5da-45b5-afd5-3a868ea5519a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.1 s, sys: 176 ms, total: 30.2 s\n",
      "Wall time: 30.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        [(Addictive, NNP), (., .), (Stressful, NNP), (...\n",
       "4        [(If, IN), (the, DT), (Steam, NNP), (comments,...\n",
       "5        [(I, PRP), (like, VBP), (the, DT), (gathering,...\n",
       "6        [(Very, RB), (well, RB), (made, VBN), (game, N...\n",
       "7        [(I, PRP), (thought, VBD), (this, DT), (would,...\n",
       "                               ...                        \n",
       "69256    [(We, PRP), (have, VBP), (Hades, VBN), (at, IN...\n",
       "69257    [(Unfortunately, RB), (can, MD), (not, RB), (r...\n",
       "69258    [(if, IN), (you, PRP), (enjoy, VBP), (soulston...\n",
       "69259    [(Great, JJ), (game, NN), (overall, JJ), (!, ....\n",
       "69260    [(The, DT), (game, NN), (is, VBZ), (pretty, RB...\n",
       "Name: review_tagged_NLTK, Length: 48713, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Directly apply nltk.postag\n",
    "\n",
    "%time review_df['review_tagged_NLTK'] = review_df['review_tokens'].apply(nltk.pos_tag)\n",
    "review_df['review_tagged_NLTK']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b418e9776e1aef",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f54b035705ebf101",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ON6_hHKS4zq4",
    "outputId": "858f70fc-6a1d-4a8e-8c9c-1c916454569b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/joh11678/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## download lemmatizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cdc3ac097bec0f15",
   "metadata": {
    "id": "imQIyvDD4xsj"
   },
   "outputs": [],
   "source": [
    "# function to lemmatize words based on different POS tag types;\n",
    "def lemmatize_POS (tagged_columns):\n",
    "  wnl = WordNetLemmatizer()\n",
    "  text=[]\n",
    "  for word, tag in tagged_columns:\n",
    "    if tag.startswith('NN'):\n",
    "      token = wnl.lemmatize(word, pos='n') # n is NOUN\n",
    "    elif tag.startswith('VB'):\n",
    "      token = wnl.lemmatize(word, pos='v') # v is VERB\n",
    "    elif tag.startswith('JJ'):\n",
    "      token = wnl.lemmatize(word, pos='a') # a is ADJ\n",
    "    elif tag.startswith('RB'):\n",
    "      token = wnl.lemmatize(word, pos='r') # r is ADV\n",
    "    else:\n",
    "      token = word\n",
    "    text.append(token)\n",
    "  #cleaned_corpus.append(text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "475eb16dd6e65765",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 494
    },
    "id": "rjCDYQF73aS8",
    "outputId": "8d196ccd-4208-4c89-d17c-a8680ff8b0be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            [Addictive, ., Stressful, ., Time, waster, .]\n",
       "4        [If, the, Steam, comment, section, be, like, e...\n",
       "5        [I, like, the, gathering, and, sneak, around, ...\n",
       "6        [Very, well, make, game, ,, every, time, I, ho...\n",
       "7        [I, think, this, would, be, too, sweaty, for, ...\n",
       "                               ...                        \n",
       "69256                       [We, have, Hades, at, home, :]\n",
       "69257    [Unfortunately, can, not, recommend, the, game...\n",
       "69258    [if, you, enjoy, soulstone, survivor, or, hade...\n",
       "69259    [Great, game, overall, !, I, really, enjoy, th...\n",
       "69260    [The, game, be, pretty, good, for, some, of, t...\n",
       "Name: review_lemma_NLTK, Length: 48713, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df['review_lemma_NLTK'] = review_df['review_tagged_NLTK'].apply(lemmatize_POS) ## apply lemmatization based on POS tag\n",
    "review_df['review_lemma_NLTK']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6ba0498d8f17f9",
   "metadata": {},
   "source": [
    "## Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f1e73b546683b5de",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B_uht_RA5FvI",
    "outputId": "d0aac00d-1f95-42c1-e70c-59edb33942e8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/joh11678/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /Users/joh11678/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "def preprocessing(tokens):\n",
    "  tokens = [token.lower() for token in tokens] # lowercasing\n",
    "\n",
    "  tokens = [token for token in tokens if not token.isdigit()] # remove digit - isdigit is a python buit-in method.\n",
    "\n",
    "  tokens = [token for token in tokens if token not in punctuation] # remove punctuations\n",
    "\n",
    "  # Remove tokens that are entirely punctuation (single or multiple)\n",
    "  tokens = [token for token in tokens if not re.fullmatch(r\"[^\\w]+\", token)]\n",
    "\n",
    "  mystopwords = set(stopwords.words(\"english\")) # use english stopwords list.\n",
    "  tokens = [token for token in tokens if token not in mystopwords] # remove stopwords\n",
    "\n",
    "  tokens = [token for token in tokens if len(token)>=3] # remove tokens with one or two characters\n",
    "\n",
    "  return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "34883cad3b2832a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 494
    },
    "id": "IsR9o8TI5QAY",
    "outputId": "d446eca0-b7f5-4b5a-b333-f105f38018a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.86 s, sys: 611 ms, total: 2.47 s\n",
      "Wall time: 2.47 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                     [addictive, stressful, time, waster]\n",
       "4        [steam, comment, section, like, every, comment...\n",
       "5        [like, gathering, sneak, around, arc, pvp, par...\n",
       "6        [well, make, game, every, time, hop, experienc...\n",
       "7        [think, would, sweaty, honestly, somehow, stop...\n",
       "                               ...                        \n",
       "69256                                        [hades, home]\n",
       "69257    [unfortunately, recommend, game, devs, deliver...\n",
       "69258           [enjoy, soulstone, survivor, hades, enjoy]\n",
       "69259    [great, game, overall, really, enjoy, hades, l...\n",
       "69260    [game, pretty, good, first, difficulty, become...\n",
       "Name: review_lemma_NLTK_final, Length: 48713, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time review_df['review_lemma_NLTK_final'] = review_df['review_lemma_NLTK'].apply(preprocessing) ## apply preprocessing to text\n",
    "review_df['review_lemma_NLTK_final']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61e245d0b377db0",
   "metadata": {},
   "source": [
    "## restringing statuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d54623de6c58061",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ReOGFE4TDycQ",
    "outputId": "4d263803-c1e2-4bea-e0ad-65811c85690f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['addictive stressful time waster'\n",
      " 'steam comment section like every comment section game expect get flame negative review lame pvp ruin solo play extraction shooter devolve see genre unpopular maybe squad mode well consistent group hard say fix much tension make game interesting possibility nearby raider hostile however game make vulnerable long looting favor first shoot strongly anyone actively try murder every player meet massive disadvantage run cool pvp guy even cheap free weapon game heavily favor ambush heavy shield little mitigate minimum feel like deal effective shield damage require form kit investment behalf attacker obviously strategy help many either expensive tedious sneak everywhere never loot anything area open line sight neither terribly fun booby trap every area loot want shooter make unpleasant fact replace anything basic loadout involve obnoxious amount time menu craft equipping let alone expensive limited availability blueprint stock item plus goal maximize loot may well run free loadout basic kit looter augment pocket rare item actually matter unsurprising many solo pvp enjoyer griefer attitude otherwise play proper pvp game instead want roam map try shoot others back engage gameplay element'\n",
      " 'like gathering sneak around arc pvp part people kill nothing start level loose faith humanity game make worth despite hour play']\n"
     ]
    }
   ],
   "source": [
    "# create a text column with tagged tokens\n",
    "review_df['review_cleaned'] = review_df['review_lemma_NLTK_final'].apply (lambda row: ' '.join(str(x) for x in row))\n",
    "# check the final text\n",
    "print(review_df['review_cleaned'].head(3).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3247f1679dbe4df0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "QnFlI3GTEc6X",
    "outputId": "2742b753-7794-4600-baac-343b30fd77e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review count before: (48713, 8)\n",
      "Review count after: (48662, 8)\n"
     ]
    }
   ],
   "source": [
    "## check rows where the cleaned review is empty\n",
    "print(\"Review count before:\", review_df.shape)\n",
    "\n",
    "review_df = review_df[review_df[\"review_cleaned\"].str.len() > 0]\n",
    "print(\"Review count after:\", review_df.shape)\n",
    "## We didn't completely clear out any entries so we don't need to worry about this so much"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba3f5d282469244",
   "metadata": {},
   "source": [
    "## Lexical Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3beae3e160f39fa8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "53bGpMZv6zyd",
    "outputId": "d52fd1f9-db56-49b4-a67b-35f23984c96d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            (Addictive, ., Stressful, ., Time, waster, .)\n",
       "4        (If, the, Steam, comments, section, is, like, ...\n",
       "5        (I, like, the, gathering, and, sneaking, aroun...\n",
       "6        (Very, well, made, game, ,, every, time, I, ho...\n",
       "7        (I, thought, this, would, be, too, sweaty, for...\n",
       "                               ...                        \n",
       "69256                       (We, have, Hades, at, home, :)\n",
       "69257    (Unfortunately, can, not, recommend, the, game...\n",
       "69258    (if, you, enjoy, soulstone, survivors, or, had...\n",
       "69259    (Great, game, overall, !, I, really, enjoy, th...\n",
       "69260    (The, game, is, pretty, good, for, some, of, t...\n",
       "Name: tokens_text, Length: 48662, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df['tokens_text'] = review_df['review_tokens'].apply(nltk.text.Text) # put tokens into text form before calculating lexical diversity\n",
    "review_df['tokens_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "92a95f3e4b31d848",
   "metadata": {
    "id": "exP1UNmT75Cx"
   },
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "  \"\"\"\n",
    "  A measure of the lexical richness of the text\n",
    "  \"\"\"\n",
    "  return len(text)/len(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a2649be0a92aad39",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "yzN6JJr977Qh",
    "outputId": "f0951913-8e64-4cbb-dbab-992cda36b925"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1.400000\n",
       "4        1.775701\n",
       "5        1.357143\n",
       "6        1.066667\n",
       "7        1.259259\n",
       "           ...   \n",
       "69256    1.000000\n",
       "69257    1.177778\n",
       "69258    1.133333\n",
       "69259    1.233333\n",
       "69260    1.105263\n",
       "Name: lexical_diversity, Length: 48662, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df['lexical_diversity'] = review_df['tokens_text'].apply(lexical_diversity) ## calculate lexical diversity\n",
    "review_df['lexical_diversity']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91464dc0cfdfb777",
   "metadata": {},
   "source": [
    "## Spellchecking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5c63a579391b4b38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UO4sTpUr9FEi",
    "outputId": "f2143b3d-7959-4f6e-8806-a793ffffb220"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspellchecker\n",
      "  Downloading pyspellchecker-0.8.4-py3-none-any.whl.metadata (9.4 kB)\n",
      "Downloading pyspellchecker-0.8.4-py3-none-any.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyspellchecker\n",
      "Successfully installed pyspellchecker-0.8.4\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "860ae85d3e2cc07",
   "metadata": {
    "id": "iyuG3zQ48KM8"
   },
   "outputs": [],
   "source": [
    "## import a spellchecker\n",
    "from spellchecker import SpellChecker\n",
    "spell = SpellChecker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bb383fdcca05feb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "kTvoks9584IZ",
    "outputId": "a0382b2d-41fe-4dd3-9d53-f41bb2c6f807"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                               {}\n",
       "4        {gameplay, pvp, )., loadout, .\", griefer}\n",
       "5                                            {pvp}\n",
       "6                                               {}\n",
       "7                                            {isn}\n",
       "                           ...                    \n",
       "69256                                           {}\n",
       "69257                    {promosed, devs, dlc, og}\n",
       "69258                              {ll, soulstone}\n",
       "69259                                      {op, ’}\n",
       "69260                                           {}\n",
       "Name: potential_misspells, Length: 48662, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df['potential_misspells'] = review_df['review_tokens'].apply(spell.unknown) ## store unknown words as potential misspells\n",
    "review_df['potential_misspells']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31cac8937fc2f8d",
   "metadata": {},
   "source": [
    "## review Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1bc82bfbef9bbe1a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "hfz_8z5n9P_e",
    "outputId": "1257acd3-85ac-48e5-8e46-1be91699c135"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          7\n",
       "4        380\n",
       "5         57\n",
       "6         16\n",
       "7         68\n",
       "        ... \n",
       "69256      6\n",
       "69257     53\n",
       "69258     17\n",
       "69259     74\n",
       "69260     21\n",
       "Name: review_length, Length: 48662, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df['review_length'] = review_df['review_tokens'].apply(len) ## calculate original review length\n",
    "review_df['review_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6bb94e5823739c79",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "m60stkE09XaW",
    "outputId": "1ae3bdf4-b353-4cee-b405-5206c932023e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          4\n",
       "4        179\n",
       "5         21\n",
       "6         10\n",
       "7         23\n",
       "        ... \n",
       "69256      2\n",
       "69257     22\n",
       "69258      5\n",
       "69259     33\n",
       "69260      9\n",
       "Name: cleaned_review_length, Length: 48662, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df['cleaned_review_length'] = review_df['review_lemma_NLTK_final'].apply(len) ## calculate review length after lemmatization\n",
    "review_df['cleaned_review_length']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b4498b55e4ebe7",
   "metadata": {},
   "source": [
    "## Write results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6c599cb26f8441cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "u153i2i_9nvU",
    "outputId": "6e7fae66-70ec-4a58-cc5d-6f05e6c2f256"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recommendationid</th>\n",
       "      <th>Appname</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_tokens</th>\n",
       "      <th>review_tagged_NLTK</th>\n",
       "      <th>review_lemma_NLTK</th>\n",
       "      <th>review_lemma_NLTK_final</th>\n",
       "      <th>review_cleaned</th>\n",
       "      <th>tokens_text</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>potential_misspells</th>\n",
       "      <th>review_length</th>\n",
       "      <th>cleaned_review_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>212664845</td>\n",
       "      <td>ARC Raiders</td>\n",
       "      <td>Addictive.  Stressful. Time waster.</td>\n",
       "      <td>[Addictive, ., Stressful, ., Time, waster, .]</td>\n",
       "      <td>[(Addictive, NNP), (., .), (Stressful, NNP), (...</td>\n",
       "      <td>[Addictive, ., Stressful, ., Time, waster, .]</td>\n",
       "      <td>[addictive, stressful, time, waster]</td>\n",
       "      <td>addictive stressful time waster</td>\n",
       "      <td>(Addictive, ., Stressful, ., Time, waster, .)</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>{}</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>212664705</td>\n",
       "      <td>ARC Raiders</td>\n",
       "      <td>If the Steam comments section is like every ot...</td>\n",
       "      <td>[If, the, Steam, comments, section, is, like, ...</td>\n",
       "      <td>[(If, IN), (the, DT), (Steam, NNP), (comments,...</td>\n",
       "      <td>[If, the, Steam, comment, section, be, like, e...</td>\n",
       "      <td>[steam, comment, section, like, every, comment...</td>\n",
       "      <td>steam comment section like every comment secti...</td>\n",
       "      <td>(If, the, Steam, comments, section, is, like, ...</td>\n",
       "      <td>1.775701</td>\n",
       "      <td>{gameplay, pvp, )., loadout, .\", griefer}</td>\n",
       "      <td>380</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>212664692</td>\n",
       "      <td>ARC Raiders</td>\n",
       "      <td>I like the gathering and sneaking around the A...</td>\n",
       "      <td>[I, like, the, gathering, and, sneaking, aroun...</td>\n",
       "      <td>[(I, PRP), (like, VBP), (the, DT), (gathering,...</td>\n",
       "      <td>[I, like, the, gathering, and, sneak, around, ...</td>\n",
       "      <td>[like, gathering, sneak, around, arc, pvp, par...</td>\n",
       "      <td>like gathering sneak around arc pvp part peopl...</td>\n",
       "      <td>(I, like, the, gathering, and, sneaking, aroun...</td>\n",
       "      <td>1.357143</td>\n",
       "      <td>{pvp}</td>\n",
       "      <td>57</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  recommendationid      Appname  \\\n",
       "0        212664845  ARC Raiders   \n",
       "4        212664705  ARC Raiders   \n",
       "5        212664692  ARC Raiders   \n",
       "\n",
       "                                         review_text  \\\n",
       "0                Addictive.  Stressful. Time waster.   \n",
       "4  If the Steam comments section is like every ot...   \n",
       "5  I like the gathering and sneaking around the A...   \n",
       "\n",
       "                                       review_tokens  \\\n",
       "0      [Addictive, ., Stressful, ., Time, waster, .]   \n",
       "4  [If, the, Steam, comments, section, is, like, ...   \n",
       "5  [I, like, the, gathering, and, sneaking, aroun...   \n",
       "\n",
       "                                  review_tagged_NLTK  \\\n",
       "0  [(Addictive, NNP), (., .), (Stressful, NNP), (...   \n",
       "4  [(If, IN), (the, DT), (Steam, NNP), (comments,...   \n",
       "5  [(I, PRP), (like, VBP), (the, DT), (gathering,...   \n",
       "\n",
       "                                   review_lemma_NLTK  \\\n",
       "0      [Addictive, ., Stressful, ., Time, waster, .]   \n",
       "4  [If, the, Steam, comment, section, be, like, e...   \n",
       "5  [I, like, the, gathering, and, sneak, around, ...   \n",
       "\n",
       "                             review_lemma_NLTK_final  \\\n",
       "0               [addictive, stressful, time, waster]   \n",
       "4  [steam, comment, section, like, every, comment...   \n",
       "5  [like, gathering, sneak, around, arc, pvp, par...   \n",
       "\n",
       "                                      review_cleaned  \\\n",
       "0                    addictive stressful time waster   \n",
       "4  steam comment section like every comment secti...   \n",
       "5  like gathering sneak around arc pvp part peopl...   \n",
       "\n",
       "                                         tokens_text  lexical_diversity  \\\n",
       "0      (Addictive, ., Stressful, ., Time, waster, .)           1.400000   \n",
       "4  (If, the, Steam, comments, section, is, like, ...           1.775701   \n",
       "5  (I, like, the, gathering, and, sneaking, aroun...           1.357143   \n",
       "\n",
       "                         potential_misspells  review_length  \\\n",
       "0                                         {}              7   \n",
       "4  {gameplay, pvp, )., loadout, .\", griefer}            380   \n",
       "5                                      {pvp}             57   \n",
       "\n",
       "   cleaned_review_length  \n",
       "0                      4  \n",
       "4                    179  \n",
       "5                     21  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7b7c2dceb6901b8e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "IhvpdyiF90y2",
    "outputId": "2987c223-3aac-4a7f-fa36-29bc2b568d93"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recommendationid</th>\n",
       "      <th>Appname</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>potential_misspells</th>\n",
       "      <th>review_length</th>\n",
       "      <th>cleaned_review_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>212664845</td>\n",
       "      <td>ARC Raiders</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>set()</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>212664705</td>\n",
       "      <td>ARC Raiders</td>\n",
       "      <td>1.775701</td>\n",
       "      <td>{'gameplay', 'pvp', ').', 'loadout', '.\"', 'gr...</td>\n",
       "      <td>380</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>212664692</td>\n",
       "      <td>ARC Raiders</td>\n",
       "      <td>1.357143</td>\n",
       "      <td>{'pvp'}</td>\n",
       "      <td>57</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>212664560</td>\n",
       "      <td>ARC Raiders</td>\n",
       "      <td>1.066667</td>\n",
       "      <td>set()</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>212664471</td>\n",
       "      <td>ARC Raiders</td>\n",
       "      <td>1.259259</td>\n",
       "      <td>{'isn'}</td>\n",
       "      <td>68</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recommendationid      Appname  lexical_diversity  \\\n",
       "0         212664845  ARC Raiders           1.400000   \n",
       "1         212664705  ARC Raiders           1.775701   \n",
       "2         212664692  ARC Raiders           1.357143   \n",
       "3         212664560  ARC Raiders           1.066667   \n",
       "4         212664471  ARC Raiders           1.259259   \n",
       "\n",
       "                                 potential_misspells  review_length  \\\n",
       "0                                              set()              7   \n",
       "1  {'gameplay', 'pvp', ').', 'loadout', '.\"', 'gr...            380   \n",
       "2                                            {'pvp'}             57   \n",
       "3                                              set()             16   \n",
       "4                                            {'isn'}             68   \n",
       "\n",
       "   cleaned_review_length  \n",
       "0                      4  \n",
       "1                    179  \n",
       "2                     21  \n",
       "3                     10  \n",
       "4                     23  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## write just the output required for section 1\n",
    "output_path = 'data/preprocessing_metadata_output.csv'\n",
    "\n",
    "review_df[['recommendationid', 'Appname', 'lexical_diversity', 'potential_misspells', 'review_length', 'cleaned_review_length']].to_csv(output_path, index=False)\n",
    "\n",
    "part1_df = pd.read_csv(output_path)\n",
    "part1_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9d9975ae62cf9b82",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "w1bhFwjM9nvU",
    "outputId": "a0df64d6-67ba-4d7a-854b-f239ac6eb0ee"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recommendationid</th>\n",
       "      <th>Appname</th>\n",
       "      <th>review_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>212664845</td>\n",
       "      <td>ARC Raiders</td>\n",
       "      <td>addictive stressful time waster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>212664705</td>\n",
       "      <td>ARC Raiders</td>\n",
       "      <td>steam comment section like every comment secti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>212664692</td>\n",
       "      <td>ARC Raiders</td>\n",
       "      <td>like gathering sneak around arc pvp part peopl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>212664560</td>\n",
       "      <td>ARC Raiders</td>\n",
       "      <td>well make game every time hop experience somet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>212664471</td>\n",
       "      <td>ARC Raiders</td>\n",
       "      <td>think would sweaty honestly somehow stop playi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recommendationid      Appname  \\\n",
       "0         212664845  ARC Raiders   \n",
       "1         212664705  ARC Raiders   \n",
       "2         212664692  ARC Raiders   \n",
       "3         212664560  ARC Raiders   \n",
       "4         212664471  ARC Raiders   \n",
       "\n",
       "                                      review_cleaned  \n",
       "0                    addictive stressful time waster  \n",
       "1  steam comment section like every comment secti...  \n",
       "2  like gathering sneak around arc pvp part peopl...  \n",
       "3  well make game every time hop experience somet...  \n",
       "4  think would sweaty honestly somehow stop playi...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## write the tokenized and cleaned output for use in later sections\n",
    "output_path = 'data/review_tokenized.csv'\n",
    "review_df[['recommendationid', 'Appname', 'review_cleaned']].to_csv(output_path, index=False)\n",
    "\n",
    "review_df = pd.read_csv(output_path)\n",
    "review_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456f78b18fc2a0a4",
   "metadata": {},
   "source": [
    "# Part 2: Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf837bf-25f8-4684-b93c-2fe34c352a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
